# **AI-Powered Voice and Vision Chatbot**

This project is an **AI-driven chatbot** designed to enhance **patient-doctor interactions** by integrating **advanced speech recognition** and **medical image analysis** capabilities.

## **Project Overview**

The **AI-Powered Voice and Vision Chatbot** bridges communication gaps in **healthcare** settings by:

- üó£ **Voice Recognition**: Uses **OpenAI's Whisper** model for precise speech transcription.
- üè• **Visual Analysis**: Leverages **Meta‚Äôs Llama 3.2** multimodal model for medical image interpretation.
- üí¨ **Human-Like Responses**: Generates **empathetic and natural** responses to patient inquiries.

## **Features**

‚úÖ **Speech-to-Text (STT)**: Converts patient speech into text using Whisper.  
‚úÖ **Image Analysis**: Processes and analyzes medical images using Llama 3.2.  
‚úÖ **Text-to-Speech (TTS)**: Responds with natural-sounding speech via gTTS and ElevenLabs.  
‚úÖ **User-Friendly Interface**: Built with **Gradio** for real-time interaction.  

## **Workflow Diagram**

![Workflow Diagram]([(https://github.com/Akash-Kadali/Conversational-AI-with-Voice-and-Visual-Capabilities/blob/main/Process%20Flow.png)])

---

## **Getting Started**

### **Prerequisites**

- **Python 3.8+**: Ensure Python is installed on your system.
- **Virtual Environment**: Recommended to manage dependencies.

### **Installation**

1Ô∏è‚É£ **Clone the Repository**:

```bash
git clone [(https://github.com/Akash-Kadali/Conversational-AI-with-Voice-and-Visual-Capabilities.git)
cd conversational_ai_with_voice_and_visual_capabilities
